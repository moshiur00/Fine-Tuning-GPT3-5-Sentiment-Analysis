{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f39ab69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2401</th>\n",
       "      <th>Borderlands</th>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will murder yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Borderlands</th>\n",
       "      <td>Positive</td>\n",
       "      <td>I am coming to the borders and I will kill you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Borderlands</th>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will kill you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Borderlands</th>\n",
       "      <td>Positive</td>\n",
       "      <td>im coming on borderlands and i will murder you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Borderlands</th>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands 2 and i will murder ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">2433</th>\n",
       "      <th>Borderlands</th>\n",
       "      <td>Neutral</td>\n",
       "      <td>i enter that gunner seat and actually fear for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Borderlands</th>\n",
       "      <td>Neutral</td>\n",
       "      <td>i then enter in that gunner seat and i fear fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Borderlands</th>\n",
       "      <td>Neutral</td>\n",
       "      <td>i enter that gunner seat and i fear for a life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2434</th>\n",
       "      <th>Borderlands</th>\n",
       "      <td>Negative</td>\n",
       "      <td>fuck it .  pic.twitter.com/Wav1bacr5j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Borderlands</th>\n",
       "      <td>Negative</td>\n",
       "      <td>Fuck it. pic.twitter.com / Wav1bacr5j</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 sentiment                                               text\n",
       "2401 Borderlands  Positive  im getting on borderlands and i will murder yo...\n",
       "     Borderlands  Positive  I am coming to the borders and I will kill you...\n",
       "     Borderlands  Positive  im getting on borderlands and i will kill you ...\n",
       "     Borderlands  Positive  im coming on borderlands and i will murder you...\n",
       "     Borderlands  Positive  im getting on borderlands 2 and i will murder ...\n",
       "...                    ...                                                ...\n",
       "2433 Borderlands   Neutral  i enter that gunner seat and actually fear for...\n",
       "     Borderlands   Neutral  i then enter in that gunner seat and i fear fo...\n",
       "     Borderlands   Neutral     i enter that gunner seat and i fear for a life\n",
       "2434 Borderlands  Negative              fuck it .  pic.twitter.com/Wav1bacr5j\n",
       "     Borderlands  Negative              Fuck it. pic.twitter.com / Wav1bacr5j\n",
       "\n",
       "[200 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Data\n",
    "import pandas as pd\n",
    "\n",
    "# Load raw tweets\n",
    "tweets_df = pd.read_csv(\"../data/raw/twitter_training.csv\", names=['sentiment', 'text'])\n",
    "tweets_df.head(200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041147e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\moshi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\moshi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\moshi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 sentiment                          cleaned_text\n",
      "2401 Borderlands  Positive         im getting borderlands murder\n",
      "     Borderlands  Positive                   coming borders kill\n",
      "     Borderlands  Positive           im getting borderlands kill\n",
      "     Borderlands  Positive          im coming borderlands murder\n",
      "     Borderlands  Positive         im getting borderlands murder\n",
      "...                    ...                                   ...\n",
      "2433 Borderlands   Neutral  enter gunner seat actually fear life\n",
      "     Borderlands   Neutral           enter gunner seat fear life\n",
      "     Borderlands   Neutral           enter gunner seat fear life\n",
      "2434 Borderlands  Negative            fuck pictwittercomwavbacrj\n",
      "     Borderlands  Negative           fuck pictwittercom wavbacrj\n",
      "\n",
      "[200 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Data Cleaning\n",
    "import re\n",
    "import emoji\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Download NLTK resources\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "# Set of English stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Function to clean tweets\n",
    "def clean_tweet(text):\n",
    "    if pd.isnull(text):\n",
    "        return \"\"\n",
    "    \n",
    "    # Remove emojis\n",
    "    text = emoji.replace_emoji(text, replace='')\n",
    "\n",
    "    # Remove URLs\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', text, flags=re.MULTILINE)\n",
    "\n",
    "    # Remove user @ references and hashtags\n",
    "    text = re.sub(r'\\@\\w+|\\#', '', text)\n",
    "\n",
    "    # Remove punctuation and numbers\n",
    "    text = re.sub(r\"[^A-Za-z\\s]\", '', text)\n",
    "\n",
    "    # Tokenize\n",
    "    tokens = word_tokenize(text.lower())\n",
    "\n",
    "    # Remove stopwords and non-alphabetic words\n",
    "    cleaned_tokens = [word for word in tokens if word.isalpha() and word not in stop_words]\n",
    "\n",
    "    # Join tokens back into one string\n",
    "    cleaned_text = \" \".join(cleaned_tokens)\n",
    "\n",
    "    return cleaned_text\n",
    "\n",
    "\n",
    "# Clean the tweets\n",
    "tweets_df['cleaned_text'] = tweets_df['text'].apply(clean_tweet)\n",
    "\n",
    "# View the cleaned tweets\n",
    "print(tweets_df[['sentiment', 'cleaned_text']].head(200))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3bf9778",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling Missing Values\n",
    "tweets_df.dropna(subset=['cleaned_text', 'sentiment'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "083ca439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Processed Data\n",
    "tweets_df.to_csv(\"../data/processed/cleaned_tweets.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
